---
title: "tiers"
author: "Huey Kwik"
date: "May 30, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(dplyr)
library(ggplot2)
library(mclust)
library(gsubfn)
library(XML)

source("util.R")

# Initialize constants
pos.list = c('qb','rb','wr','te','k','dst')

kYear = 2015
kCutoffs = c(QB = 24, RB = 40, WR = 60, TE = 24, K = 24, DST = 24)
kTiers = c(QB = 8, RB = 9, WR = 12, TE = 8, K = 5, DST = 6)

# Plotting
font = 3.5
barsize = 1.5  
dotsize = 2  
```

## Introduction

A couple years ago, I encountered a [New York Times article](http://nyti.ms/1t6Bgc3) 
by Boris Chen that explained a way to use machine learning to improve your starting lineup 
in fantasy football. 

Every week, legions of fantasy football experts come up with their lists of player
rankings. [FantasyPros](https://www.fantasypros.com/) aggregates these and comes up with an Expert Conensus Ranking. 
Chen applies a [Gaussian mixture model](http://bit.ly/1VKWt6S) to the rankings, 
which produces tiers of similarly ranked players. 

The tiers lend themselves to easier decision-making. For instance, one should draft
players in higher tiers versus other popular tactics, e.g. filling a specific position
early.

In this project, I show that we can improve upon these tiers by clustering based
on projected points instead of ECR. When run against the 2015 season data, my 
technique seems to perform better.

## Grabbing Data

In order to do this project, I needed the following data for the 2015 season:

* Projected and actual scores from [Fantasy Football Analytics](apps.fantasyfootballanalytics.net/projections)
* Expert Consensus Rankings from FantasyPros.

The projected scores for each week are the average of the scores from CBS, ESPN,
FantasyFootball Nerd, FantasySharks, FFToday, NFL NumberFire, and YahooSports. 
I used Yahoo! standard scoring.

I wrote a modified version of [Chen's code](https://github.com/borisachen/fftiers) 
to download the ECR data:

```{r download ECR}
download.data = function(week, pos.list) {
  for (mp in pos.list) {
 	 	# Remove old data files.
    rmold1 = paste('rm data/2015/week-', week, '-',mp,'-raw.xls', sep='')
  	system(rmold1)
  	
  	urlStr = fn$identity("http://www.fantasypros.com/nfl/rankings/`mp`.php?week=`week`&export=xls")
  	dlPath = fn$identity("data/2015/week-`week`-`mp`-raw.xls")
  	
	  rmold2 = paste('rm ~ data/2015/week_', week, '_', mp, '.tsv', sep='')
  	system(rmold2)
    download.file(urlStr, destfile=dlPath)  
    sedstr = paste("sed '1,4d' data/2015/week-", week, '-',mp,'-raw.xls', 
  			  ' > data/2015/week_', week, '_', mp, '.tsv',sep="")
    system(sedstr)
  }	  
}

# TODO(huey): Error when trying to download using knitr, but works otherwise.
# sapply(1:17, function(week) download.data(week))
```

## Evaluating Accuracy

Accuracy of a tier is defined as the percentage of time a higher tier results
in a higher median score than a lower tier.

```{r}
computeAccuracy = function(scores, tiers) {
  n_tiers = length(unique(tiers))
  n_correct = 0
  n_comparisons = 0
  
  medians = c()
  for (i in seq(n_tiers)) {
    median = median(scores[tiers == i])
    medians = c(medians, median)
  }
  
  for (i in seq(n_tiers-1)) {
    curr_median = medians[i]
    below_medians = medians[(i+1):n_tiers]
  
    comparisons = sapply(below_medians, function(x) curr_median > x)
  
    n_correct = n_correct + sum(comparisons)
    n_comparisons = n_comparisons + length(comparisons)
  }
  
  return(n_correct / n_comparisons)
}
```

# Computing Tiers
Here I compare clusters generated from ECR to those generated from projections.

Caveats

* TierECR doesn't match Chen's completely. 
  * This is because his site only the latest
set of tiers, i.e. Week 17. 
  * He also uses visual inspection to determine the number of clusters and will
  change them each week (he publishes a new set of tiers each week)

```{r integrate_data, warning = FALSE}
tier_ecr_accuracy = data.frame()
tier_proj_accuracy = data.frame()

for (week in seq(17)) {
  # Parser warnings are due to trailing comma at the end of each row
  sdf = read_csv(fn$identity("data/2015/FFA-CustomRankings-Week-`week`.csv"))
  sdf$Week = week
  sdf$actualPoints = as.numeric(sdf$actualPoints)
  sdf$actualPoints[is.na(sdf$actualPoints)] = 0
  
  week_tier_ecr_accuracy = c()
  week_tier_proj_accuracy = c()
  
  for (pos in toupper(pos.list)) {
    # print(paste("Position: ", pos))
    
    ## Calculate TierProj
    pos_df = sdf %>% filter(position == pos, positionRank <= kCutoffs[pos])
    
    proj_fit = Mclust(pos_df$points, G = kTiers[pos])
    n_clusters = length(unique(proj_fit$classification))
    
    # Sometimes the model isn't able to fit K clusters
    k = kTiers[pos] - 1
    while (n_clusters == 0) {
      proj_fit = Mclust(pos_df$points, G = k)
      n_clusters = length(unique(proj_fit$classification))
      k = k - 1
    }
    
    # Reversing so that highest projected points gets Tier 1 
    pos_df$TierProj = factor(proj_fit$classification)
    levels(pos_df$TierProj) = rev(levels(pos_df$TierProj))
    levels(pos_df$TierProj) = n_clusters:1
    
    ## Calculate TierECR
      
    # Load ECR data for the week
    ecr_df = read_tsv(fn$identity("data/2015/week_`week`_`tolower(pos)`.tsv"))
    ecr_df = ecr_df[1:kCutoffs[pos], ]  # The data is ordered from best rank to worst rank  
    names(ecr_df) = make.names(names(ecr_df))
      
    # Calculate tiers based on average rank
    fit = Mclust(ecr_df$Avg.Rank, G = kTiers[pos])
    ecr_df$TierECR = factor(fit$classification)
    levels(ecr_df$TierECR) = 1:length(unique(fit$classification))
    ecr_df$nchar = nchar(as.character(ecr_df$Player.Name))  # For formatting later
      
    # Calculate position rank, negative so lowest rank will be on top in the plot
    # below
    ecr_df$position.rank = -seq(nrow(ecr_df))
    
    plot = FALSE
    if (plot == TRUE) {
      # We put Avg.Rank as y because geom_errorbar requires ymin/ymax. We then flip the 
      # coordinates.
      p = ggplot(ecr_df, aes(x = position.rank, y = Avg.Rank))
      p = p + geom_errorbar(aes(ymin = Avg.Rank - Std.Dev/2, ymax = Avg.Rank + Std.Dev/2, width=0.2, colour=TierECR), size=barsize*0.8, alpha=0.4)
      p = p + coord_flip()
      p = p + geom_text(aes(label=Player.Name, colour=TierECR, y = Avg.Rank - nchar/6 - Std.Dev/1.4), size=font)
      p = p + scale_x_continuous("Expert Consensus Rank")
      p = p + ylab("Average Expert Rank")
      #p
      
      # Output the plots somewhere so I can look at them
      out_dir = fn$identity("out/`kYear`/week`week`/png/")
      out_path = fn$identity("`out_dir`week-`week`-`pos`.png")
      dir.create(out_dir, recursive = TRUE)
      ggsave(file = out_path, width = 9.5, height = 8, dpi = 150)
    }
    
    if (pos == "DST") {
      ecr_scores = inner_join(ecr_df, pos_df, by = c("Team" = "team"))
    } else {
      all_pos_df = sdf %>% filter(position == pos)
      ecr_scores = inner_join(ecr_df, all_pos_df, by = c("Player.Name" = "playername"))
    }
    
    acc = computeAccuracy(pos_df$actualPoints, pos_df$TierProj)
    acc_ecr = computeAccuracy(ecr_scores$actualPoints, ecr_scores$TierECR)
    
    week_tier_proj_accuracy  = c(week_tier_proj_accuracy, acc)
    week_tier_ecr_accuracy = c(week_tier_ecr_accuracy, acc_ecr)
  }

  tier_proj_accuracy = rbind(tier_proj_accuracy, week_tier_proj_accuracy)
  tier_ecr_accuracy = rbind(tier_ecr_accuracy, week_tier_ecr_accuracy)

  names(tier_proj_accuracy) = toupper(pos.list)
  names(tier_ecr_accuracy) = toupper(pos.list)
}
```

# Results

It appears that clustering based off of projections performs slightly better.

```{r}
  round(tier_proj_accuracy * 100, 1)

  round(tier_ecr_accuracy * 100, 1)

  mean_proj = sapply(tier_proj_accuracy, mean)
  mean_tier = sapply(tier_ecr_accuracy, mean)
  
  round(mean_proj * 100, 1)
  round(mean_tier * 100, 1)
```


### Idea 2: Grid search
Example: Suppose I was trying to separate RBs into two tiers, where would I draw the line?
- I could do essentialy binary search, say the range is 0-400 projected points
- Draw the line at 200
- Cost function -> accuracy mentioned below

Generalize for k 


```



